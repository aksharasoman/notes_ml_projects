{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Chatbot using Gemini API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 0: Configure API key\n",
    "\n",
    "The Python SDK for the Gemini API is contained in the google-generativeai package. \n",
    "\n",
    "Install dependency using:\n",
    "*pip install -q -U google-generativeai\n",
    "*\n",
    "\n",
    "Do not check an API key into your version control system but assign it as an environment variable instead:\n",
    "export API_KEY=<YOUR_API_KEY>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-generativeai\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# genai.configure(api_key=os.environ[\"API_KEY\"])\n",
    "genai.configure(api_key=\"AIzaSyAlo_uV3_NtCkMENTEhpZFftrMhOiiufbQ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use system instructions to steer the behavior of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_instr = \"\"\"You are OrderBot, an automated service to collect orders for a pizza restaurant. \n",
    "You first greet the customer, then collects the order,\n",
    "and then asks if it's a pickup or delivery.\n",
    "You wait to collect the entire order, then summarize it and check for a final \n",
    "time if the customer wants to add anything else. \n",
    "If it's a delivery, you ask for an address. \n",
    "Finally you collect the payment.\n",
    "Make sure to clarify all options, extras and sizes to uniquely \n",
    "identify the item from the menu.\n",
    "You respond in a short, very conversational friendly style. \n",
    "The menu includes \n",
    "pepperoni pizza  12.95, 10.00, 7.00 \n",
    "cheese pizza   10.95, 9.25, 6.50 \n",
    "eggplant pizza   11.95, 9.75, 6.75 \n",
    "fries 4.50, 3.50 \n",
    "greek salad 7.25 \n",
    "Toppings: \n",
    "extra cheese 2.00, \n",
    "mushrooms 1.50 \n",
    "sausage 3.00 \n",
    "canadian bacon 3.50 \n",
    "AI sauce 1.50 \n",
    "peppers 1.00 \n",
    "Drinks: \n",
    "coke 3.00, 2.00, 1.00 \n",
    "sprite 3.00, 2.00, 1.00 \n",
    "bottled water 5.00 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=sys_instr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Receive Prompts and Save Context and Generate chat responses\n",
    "*I searched for gemini api help docs.* \n",
    "\n",
    "**ChatSession** class of gemini enables us to have freeform conversation over multiple turns. We dont have to store conversation history as a list.\n",
    "\n",
    "Example: [Build an interactive chat](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#chat)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ChatSession.send_message** method returns the same *GenerateContentResponse* type as **GenerativeModel.generate_content**. It also appends your message and the response to the chat history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outline of chat using gemini api\n",
    "```\n",
    "model=genai.GenerativeModel( \\\n",
    "  model_name=\"gemini-1.5-flash\") \\\n",
    "chat = model.start_chat( \\\n",
    "    history=[ \\\n",
    "        {\"role\": \"user\", \"parts\": \"Hello\"}, \n",
    "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},\n",
    "    ]\n",
    ")\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "print(response.text)\n",
    "response = chat.send_message(\"How many paws are in my house?\")\n",
    "print(response.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2.1 Initialize the chat\n",
    "chat = model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_messages(_):\n",
    "    prompt = inp.value_input\n",
    "    inp.value = ''\n",
    "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "    response = chat.send_message(context) \n",
    "    context.append({'role':'model', 'parts':f\"{response}\"})\n",
    "    panels.append(\n",
    "        pn.Row('user:', pn.pane.Markdown(prompt, width=600)))\n",
    "    panels.append(\n",
    "        pn.Row('model:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "    return pn.Column(*panels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Task 3: Build GUI \n",
    "\n",
    "import panel as pn\n",
    "pn.extension() #initialization\n",
    "\n",
    "panels = [] # collect display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
    "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883db41159854ff9857ad686d0160b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'dd119c99-62f0-4f55-a5b6-b85f7a0dd9a6': {'version…"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chat_area_input = pn.chat.ChatAreaInput(placeholder=\"Type something, and press Enter to submit!\")\n",
    "output_markdown = pn.bind(output, chat_area_input.param.value)\n",
    "pn.Row(chat_area_input, output_markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
